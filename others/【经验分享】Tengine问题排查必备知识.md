注：Tengine是由淘宝网发起的Web服务器项目。它在Nginx的基础上，针对大访问量网站的需求，添加了很多高级功能和特性。在本文中可认为与Nginx 等同。

**假如日志欺骗了你，不要悲伤，看下这篇文章吧。**
## 1 前言
        在日常排查问题或者同用户连调的时候，是否经常会遇到，在access_log 里看到用户请求很快，但用户却反馈很慢；
    在日志中看到用户的请求都成功了，用户却反馈说有大量失败失败等一系列自己看到的和用户描述不一致的问题，有时候会
    怀疑用户搞错了，等用户贴出截图的时候又怀疑自己搞错了，如果有遇到这类问题，这篇文章或许对你有帮助。
        本文主要介绍了Tengine中关于“时间”及”缓存“的一些问题，介绍一些问题发生的原因，并从用户角度及服务端角度尝
    试分析这些问题。

## 2 Tengine打access_log 时机
        在接着往下介绍之前，先看下Tengine打access_log 的时机，清楚了这个后，再接着往下看会清晰很多。
    Tengine的access_log 是在Tengine”认为“这个请求结束后才打的，对于正常请求，Tengine会在请求最后一个字节发出
    后认为请求结束；对于异常请求，当Tengine判断连接超时或者异常断开，无法再发送和接收数据的时候。通常情况下可以认
    为Tengine在请求结束后随即会打出日志。
   
## 3 如何理解Tengine的"请求最后一个字节发出"
        Tengine认为请求最后一个字节发出后，该请求就结束了，其实最后一个字节发出可以理解为最后一串数据发出，这里
    是“发出“ 而不是用户收到，指的是将最后一串数据填到协议栈中，只要send 成功返回，Tengine就认为结束了，至于数
    据是否被客户端收到那就是协议栈和网络上的事情了，Tengine不会去关心。 
    
## 4 为什么服务端看到的延时同客户端不一致
### 4.1 服务端 request_time_msec 的含义
        要搞清楚这个问题，首先我们要明确Tengine access_log 中的“request_time_msec” 字段到底表达了什么含义。
    我们先看下官方文档是怎么说的：
    $request_time
        request processing time in seconds with a milliseconds resolution; time elapsed between 
    the first bytes were read from the client and the log write after the last bytes were sent 
    to the client
    这个字段表示的是从请求的第一个字节开始到请求最后一个字节发出后所经历的时间。
    这里其实包含如下几点信息：
    1 建连的时间是不会被算进去的。
    2 如果是HTTPS 请求，建连及HTTPS 握手的时间都不会被算进去。
    3 最后一个字节发出后Tengine认为请求结束，数据仅仅是填在协议栈中，从协议栈Buffer中的数据发送给用户的这段时间
      是不被算进去的。
    4 连接挥手的过程是不会被算进去。
    注：从长连接的角度去看，上述1、2、4的时间不被算进去还是好理解的。
    
    
### 4.2 客户端看到的E2E 时间
    4.1 中分析的request_time_msec从服务器端看到的请求E2E 时间，而用户看到的时间，假设用户用curl 去测试：
        time curl https://bucket.oss-cn-hangzhou.aliyuncs.com/object
    那么上面4.1 提到的几点不会算到服务器端时间的计算逻辑里的，除了4都会被客户端计算进去。
    针对延时不一致，下面我们从HTTP 的上传下载，具体分析一下这个延时区别，是否差，差多少。
    
### 4.3 上传类请求延时差异  
        针对于上传来说，服务器端和客户端看到的延时差异不大，相差一个握手/和最后返回的Header发送回去的时间。
    握手到服务器端收到请求首字节 2rtt，请求完成后返回的HEADER 数据一般不会很大可以塞在1个cwnd 内发完，需要一个0.5 
    个 rtt，，一共是2.5个rtt。 如果是长连接，忽略三次握手的话，那么看到的差异为1个rtt。
        因此针对上传类请求，客户端和服务器端看到的延时差距为2.5 个RT，如果是长连接(非连接上首个请求）的话差异为1个rtt。
        
### 4.4 下载类请求延时差异 
        关于下载请求的延时差异会稍微复杂一些。上传的情况下，服务器只会有HTTP 状态码和一些HTTP Header，通常一个rtt 就
    可以发完。 而下载，通常服务器会有较多的数据发送给客户端，Tengine把最后一串数据填在协议栈的Buffer里，如果再Buffer 
    中的数据能在一个rtt内发完，那么同上传类请求一致，否则就会比上传类请求的差异大。至于协议栈Buffer 中最后一串数据花多
    长时间能发送到客户端，这个就不太好估计了，取决于当时的网络状况及当时的用塞窗口大小，需要具体情况具体分析。
       在网络情况不错并且服务器端Buffer 配置较小情况下，通常差距不大，但是如果客户端网络差，而服务器端Buffer 配置较大
    的情况下，差距会比较大。比如此时客户端网络比较差，只达到100KB/s, 而服务器端协议栈Buffer 配置的较大，为1M，Tengine
    最后一串数据把1M Buffer 填满后Tengine认为请求已经结束了，而实际上客户端在10s 之后才完整的收到请求应答数据，才认为结
    束。大家可以用wget 测试一下，分别观察下服务器端和客户端看到的请求时间：
    wget your-bucket.oss-cn-hangzhou.aliyuncs.com/tmp/1m-file --limit-rate=10k --debug
    注： wget 这个限速是在应用层面做的，测试看到的时间差异除了服务端Buffer 的原因，还有客户端Buffer 的原因，数据到达客
    户端协议栈，而应用因限速而迟迟不读。
    
### 4.5 总结
        服务器端看到的E2E 时间“request_time_msec” 时间是Tengine收到请求的首字节开始，到最后一个字节写到协议栈的时间。
    客户端看到的E2E时间相比服务器多了：客户端建联及HTTPS 握手时间、请求首字节发送到服务器的时间、外加Tengine认为请求结束
    后协议栈将Buffer中的数据递送到客户端的时间。
        因此当客户抱怨延时高而服务器端看到却很快的时候，可能客户说的也对，你看到的也对，这时候就需要根据上述分析，判断具体
    是哪里导致客户端和服务器端看到延时差距，进而快速定位问题。
 
 **服务器端慢是真的慢，但是服务器端看到快，可不一定真的快。**   
    
## 5 服务器端看到的请求成功和客户端看到的请求成功
    接下来分析的都是小概率事件，正常情况下通常不会遇到，主要针对出问题时的分析。
    服务器端看到的成功，是服务器端正确处理这个请求，并把数据发送到协议栈后，服务器就会认为请求已经成功。
    客户端看到请求成功，是收到服务器端返回的状态码及完整的body 后才认为请求成功。
    
### 5.1 access_log 看到的200 OK
    access_log 里的状态码，只要请求的header 已经发出去，那么状态码就确定了，access_log 里面打出来的状态码也是确定的。
    如果是上传类请求，access_log 里打印出状态码为200，那么请求一定是成功了（但是客户端不一定能感知到这个成功）。
    如果是下载类请求，access_log 里打印出来的状态码是200，那么请求不一定成功，可能body 并未发完请求就异常结束了。
    
### 5.2 写到协议栈里的数据不一定能发送出去
        Tengine把数据写到协议栈的Buffer中后，从Tengine的角度来说，可以认为数据已经发往客户端了，但从实际角度来看，数据写
    到协议栈仅仅是写到协议栈，至于写到协议栈的数据是否能否真正被发送出去，是不一定的。在协议栈数据还没发出去之前可能网络中
    断了，或者连接被reset 了，都会可能发生。这是造成客户端和服务器端看到有差异的一个主要原因。
        
      有的同学会问，TCP 不是可靠的传输协议嘛，怎么会发不过去？建议看下这篇文章，就明白TCP 的可靠性具体指的是什么了
      https://blog.csdn.net/dog250/article/details/82177299
    
## 6 单连接最低下载速度
### 6.1 为什么会有最低下载速度限制
        针对系统性能指标，通常我们会描述一个单连接峰值吞吐的数值，但是实际上一个还有一个最低速度的限制。那么这个最低速度是
    怎么来的呢。
        一个正常C/S 架构的系统，通常会有很多Buffer，会设置很多超时时间，针对Tengine会有send_timeout，recv_timeout，
    keepalive_timeout等各种超时限制。这就会造成系统会有一个最小下载速度的限制。
        像上面描述的各类超时时间，其实是会随着各类网络事件触发设置及更新。再Linux 环境下，套接字可写就是其中一个事件，如果
    套接字长时间不可写，超过Tengine配置的send_timeout，那么就会触发超时，引发Tengine主动断开连接，甚至reset 连接。Linux
    TCP 套接字在该该套接字上的剩余Buffer空间大于总Buffer 1/3 才会被epoll 等“反应堆”返回可写，也就是说，如果Buffer 被
    填满后，在timeout时间内，Buffer 中的数据1/3 还没被发出去的话，就会触发定时器超时，导致请求异常中断。假设Buffer 配置
    的是512k，send_timeout配置的是30s。那么必须在30s 内发送出去170k才行，也就是最低要达到5.69KB/s 的速度才行。

### 6.2 如何获取系统最低下载速度
    正常情况下，我们可以通过分析系统中各个Buffer 的大小及超时时间计算出一个理论的最低下载速度，但是一个复杂的系统，很难理
    清楚或者找到各个位置的Buffer 大小及超时时间。因此我们可以利用wget 的 --limit-rate 功能进行二分测试，直到找到最低下
    载速度的零界点，注意下载的时候文件不要选择太小，选择太小了会测试不出来，当然也不要太大，太大了会造成测试时间过长，设置为
    系统最大buffer 的2倍左右即可。
    
    二分测试过程：
    low_rate = 0k, up_rate = 100k
    deviation = 5k
    while up_rate - low_rate < deviation
       mid_rate = (low_rate + up_rate)/2
        wget url --limit-rate mid_rate
        if succ then 
            up_rate = mid_rate 
        else 
           low_rate = mid_rate
         
    print low_rate, up_rate 

    如下是测试OSS 最低下载速度：
    单连接持续 5k       以内速度必然出问题(一般持续30s+出问题）
    单连接持续 5 ~10k   以内速度随机出问题，看系统状况（比较具有偶然性）
    单连接持续 10k+     基本不出问题
    
    根据上述6.1 中的理论和6.2 中的测试方法，我们甚至可以测试出来服务器端设置的sndbuf 有多大。
 

### 6.3 如何解决
        在正常情况下，这个最低下载速度并不会造成什么问题，因为大家都想方设法让速度更快，但是有些计算密集型的场景，可能会遇
    到这个问题。比如说之前遇到一个OSS 客户，从OSS 一个文件中读10k 数据，处理30s，然后再读10k 数据，再处理30s，处理一段
    时间后发现服务器端数据没发完就莫名其妙关闭连接了。其实就是遇到“最低下载速度问题”了。
        针对上述情况，客户端不要在一个请求上一条连接反反复复缓慢读数据，如果文件不大，可以考虑一次性全读出来，放内存或者本
    地再慢慢处理。如果文件太大，可以使用RangeGet，需要多少数据就从服务器端RangeGet 读多少。     
注：针对上传类请求，通常来说没有速度下限要求。

### 6.4 为什么复现不出来
       有同学使用wget/curl 的limit_rate 功能把连接速度限制到很低，但是复现不出来最低下载速度的问题，这是因为测
    试的文件太小了，测试的文件大小需要比客户度的rcvbuf + 服务端的sndbuf 还要大才能测试出来，否则数据堆在两端的
    协议栈里，是触发不到应用的超时时间限制的。

## 7 access_log 中的400 408 及499 
### 7.1 产生原因
    400 是很普通的错误码，但是在Tengine里也有不是普通“400” 的时候，在这里我们只介绍非普通400 的情况。
    408 及499在Tengine中是不会作为错误码返回给用户的（除非upstream 返回了），只是Tengine利用了这两个状态码标识请求的一
        种完成状态。这两种错误码都是和时间相关，但是是不同场景下产生，都是在服务端才能看到的状态，客户端是感知不到的。

    400，如果用户请求数据还未发完之前，客户端主动断开或者连接异常断开（如被reset 掉），在Tengine的access_log 中计为400。
    499，客户端关闭请求，在proxy 场景下确切的说是客户端先于proxy upstream 返回前断开，Tengine在做proxy 的情况下
       （fastcgi_pass/proxy_pass 等），同一请求链路上，客户端与Tengine的连接先于Tengine后端返回前断开，此时在Tengine 
         access_log中计为499 的日志。
    408，客户端请求超时，确切说客户端发送数据超时，客户端向服务器发送请求数据时中间因某种原因中断了一会，引起服务器端读数
         据超时，此时在Tengine access_log 中会记为408。注意，发送header和发送body可能会有不同的超时时间。
    
### 7.2 如何复现
    400 请求数据发完之前提前断开连接, nc 建立连接后输入完成Host 头部后Ctrl + c 断掉, 或者发送PUT 请求在body 没有发送
        完成之前Ctrl + c 掉
    408 客户端发送超时, nc 建立连接后输入完成Host 头部后等待连接超时, 或者在Body 发送完成之前等待连接超时
    499 客户端在服务器返回之前提前关闭连接 直接Curl，在服务器返回之前Ctrl + c 掉, Tengine在等待upstream返回，此时客户
        端连接已经断开. 可能你的手速没服务端处理的快，可以找一些服务器处理相对耗时的请求来复现，比如OSS的大图片处理。
    
     注：用public-read-write权限的 bucket 进行测试
    
### 7.3 是否异常
        一般正常情况下，400、408、499 这三个状态码出现的会比较少，日志中偶尔零星出现一些也不是什么大问题，如果大量出现，那
     就可能出问题了。
        如果日志中大量出现400，如果请求的request_time_msec 很小，优先排查是否是客户端问题，如果这个时间很大，请检查服务器
     压力是否过大，是否有hang住情况。如果服务器端hang 住，请求在发送的时候数据堆在Tengine里，服务器端长时间不读，造成客户端
     超时断开连接，此时Tengine会产生大量因客户端发送超时而提前断连造成的400.
        如果日志中大量出现499，如果请求的request_time_msec 很小（ms 级别），需要排查是否是客户端问题，如果这个时间很大，
     需要从两个方向排查：
        1 检查用户请求，是否后端处理确实需要很长时间，而客户端设置的超时时间又很短，此时需要客户端调整超时时间，否则客户端
          的重试可能会导致雪崩（如果没有限流的话）
        2 检查服务器是否压力过大，是否有hang 住的情况，如果后端持续不返回客户端提前断开的话就会造成大量499.
     
     这三个状态码出现，多多少少都是有些异常的，通常情况下，我们需要快速判断是服务器端的异常还是客户端的异常，从而快速定位问题。

     当然上述描述的情况也不是绝对的，有时候需要特殊场景特殊分析。
     
     
## 8 总结
        学会分析access_log 在日常调查问题中会方便很多，理解access_log 中一些特殊状态码的含义及出现的场景，会让调查问题事
    半功倍。同时对C/S 系统上Buffer 的理解也可以加快调查问题的速度，同时指导设置Buffer 的大小，解决系统在大压力下出现的一些
    性能及其他一些奇怪问题。


**上述信息由笔者翻阅源码及问题排查经验所得，如有错漏，敬请指出**




